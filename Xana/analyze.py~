import numpy as np
import multiprocessing as mp
from queue import PriorityQueue
from XpcsAna.pyxpcs3 import pyxpcs
from XsvsAna.pyxsvs3 import pyxsvs
from SaxsAna.pysaxs3 import pysaxs
from misc.xsave import save_result
from multiprocessing.managers import SyncManager
from helper import *
import time
from ProcData.Xdata import Xdata
from Decorators import Decorators
from misc.xsave import mksavdir, save_result, make_filename


class MyManager(SyncManager):
    pass


def Manager():
    m = MyManager()
    m.start()
    return m


class Xana(Xdata, ):

    def __init__(self, **kwargs):
        super(Xdata).__init__(**kwargs)
        self.setup = None
        self.setupfile = kwargs.pop('setupfile', '')

    def load_setup(self, filename=None):
        try:
            if filename is None and self.setupfile is None:
                print('No setup defined.')
            else:
                path, fname = make_filename(self, 'setupfile', filename)
                self.setupfile = path + fname
                self.setup = pickle.load(open(self.setupfile, 'rb'))
                self.init_analysis_methods()
                print('Loaded setupfile:\n\t{}.'.format(self.setupfile))
        except FileNotFoundError:
            print('No setup defined.')

    def make_setup(self, **kwargs):
        keys = ['ctr', 'distance', 'lambda', 'pix_size']
        mesg = [('beam center x [pixel]', 'beam center y [pixel]'),
                ('sample-detector distance [m]',),
                ('wavelength [A]',),
                ('pixel size x [um]', 'pixel size y [um]')
                ]
        setup = {}
        for k, m in zip(keys, mesg):
            if k in kwargs:
                inp = kwargs[k]
            else:
                inp = []
                for mi in m:
                    inp.append(input(mi+'\t'))
            if k == 'ctr':
                inp = np.array(inp).astype('int32')
            else:
                inp = np.array(inp).astype('float32')
            setup[k] = inp
        self.setup = setup

    def save_setup(self, filename=None, **kwargs):
        if filename is None:
            filename = input('Enter filename for setupfile.\t')
        self.setupfile = save_result(
            self.setup, 'setup', self.savdir, filename, **kwargs)

    @Decorators.input2list
    def analyze(self, series_id, method, first=0, last=None, handle_existing='next',
                nprocs=4, nread_procs=4, chunk_size=100, verbose=True, dark=None,
                dtype=np.float32, filename='', read_kwargs={}, **kwargs):

        for sid in series_id:
            if verbose:
                print('\n\n#### Starting %s Analysis ####\nSeries: %d in folder %s\n' %
                      (method, sid, self.datdir))
                print('Using {} processes to read data.'.format(nread_procs))

            if last is None:
                last = self.meta.loc[sid, 'nframes']

            # if dark is not None:
            #     if type(dark) == int:
            #         print('Loading DB entry {} as dark.'.format(dark))
            #         dark = self.xana.get_item(dark)['Isaxs']

            read_opt = {'first': (first,),
                        'last': (last,),
                        'dark': dark,
                        'verbose': False,
                        'dtype': dtype,
                        'qsec': self.setup['qsec'],
                        'output': '2dsection',
                        'nprocs': nread_procs
                        }
            read_opt.update(read_kwargs)

            qsec = self.setup['qsec']
            proc_dat = {'nimages': last-first,
                        'dim': (qsec[1][0]-qsec[0][0]+1, qsec[1][1]-qsec[0][1]+1)
                        }

            fmax = self.meta.loc[sid, 'nframes']
            chunks = [np.arange(first + i*chunk_size,
                                min([min(first + (i + 1)*chunk_size, last), fmax]))
                      for i in range(np.ceil((last - first) / chunk_size).astype(np.int32))]

            # Register a shared PriorityQueue
            MyManager.register("PriorityQueue", PriorityQueue)
            m = Manager()
            dataQ = m.PriorityQueue(nread_procs)
            indxQ = m.PriorityQueue()
            #dataQ = mp.Queue(nread_procs)
            #indxQ = mp.Queue()

            # add queues to read and process dictionaries
            read_opt['dataQ'] = dataQ
            read_opt['indxQ'] = indxQ
            read_opt['method'] = 'queue_chunk'
            proc_dat['dataQ'] = dataQ

            for i, chunk in enumerate(chunks):
                indxQ.put((i, chunk))

            # h5 files can only be opened by one process at a time and, therefore,
            # the processes have to acquire a lock for reading data
            lock = 0
            if 'h5' in self.fmtstr:
                lock = mp.Lock()
                read_opt['lock'] = lock

            procs = []
            for ip in range(nread_procs):
                procs.append(mp.Process(target=self.get_series,
                                        args=(sid,), kwargs=read_opt))
                procs[ip].start()
                time.sleep(2)

            if method == 'xpcs':

                saxs, dt = self.get_xpcs_args(**kwargs)
                savd = pyxpcs(proc_dat, self.setup['qroi'], dt=dt, qv=self.setup['qv'],
                              saxs=Isaxs, mask=self.mask, ctr=self.setup['ctr'],
                              qsec=xana.setup['qsec'][0], **kwargs)

            elif method == 'xsvs':
                
                t_e = self.get_xsvs_args(**kwargs)
                savd = pyxsvs(proc_dat, self.setup['qroi'], t_e=t_e, qv=self.setup['qv'],
                              qsec=self.setup['qsec'][0], **kwargs)
                
            elif method == 'saxs':
                proc_dat = {'read_dat':self.get_series, 'sid':sid}
                savd = pysaxs(proc_dat, **kwargs)

            else:
                raise ValueError('Analysis type %s not understood.' % method)

            # stopping processes
            for ip in range(nread_procs):
                procs[ip].join()

            # closing queues
            # dataQ.close()
            # dataQ.join_thread()
            # indxQ.close()
            # indxQ.join_thread()

            f = self.datdir.split('/')[-2] + '_s' + \
                str(self.meta.loc[sid, 'series']) + filename
            savfile = save_result(
                savd, method, self.savdir, f, handle_existing)
            
            xana.add_db_entry(sid, savfile)

    def get_xpcs_args(self, saxs=None, **kwargs):
        ''' Get Saxs and delay time for XPCS analysis.
        '''
        if saxs == 'compute':
            print('Calculating average SAXS image.')
            Isaxs = obj.saxs(sid, filename=filename, handle_existing=handle_existing,
                             return_saxs=True,
                             **read_data_opt)[0]['Isaxs']
        elif type(saxs) == int:
            print('Loading average SAXS from database entry {}'.format(saxs))
            Isaxs = obj.get_item(saxs)['Isaxs']
        else:
            Isaxs = saxs

        dt = 0
        for attr in ['t_delay', 't_exposure', 't_readout', 't_latency', 'rate', 'pulseLength']:
            if attr in self.meta.columns:
                item = self.meta.loc[sid, attr]
                if attr == 'rate':
                    dt += 1/item
                elif attr == 'pulseLength':
                    dt += item * 1e-15
                else:
                    dt += item
                    if attr == 't_delay':
                        break

        return saxs, dt

    def get_xsvs_args(self, ):
        ''' Get exposure time for XSVS analysis
        '''
        t_e = 0
        for attr in ['t_exposure', 'pulseLength']:
            if attr in self.meta.columns:
                item = self.meta.loc[sid,attr]
                if attr == 'pulseLength':
                    t_e += item * 1e15           
                else:
                    t_e += item

        return t_e
